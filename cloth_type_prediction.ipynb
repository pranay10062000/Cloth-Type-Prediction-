{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cloth_type_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvSf09n3jRr7C6xwNzso1p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay10062000/Cloth-Type-Prediction-/blob/main/cloth_type_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE6_LMbahpO1"
      },
      "source": [
        "\n",
        "#Import necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsKkdQd7iMMV"
      },
      "source": [
        "# Load fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh4fvf9hiOrG",
        "outputId": "6108fc02-4ec9-4160-9dec-b7954f2219bf"
      },
      "source": [
        "# Explore the dataset\n",
        "# Check the shape and size of x_train, x_test, y_train, y_test\n",
        "print (\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
        "print (\"Number of labels in training data: \" + str(len(y_train)))\n",
        "print (\"Dimensions of a single image in x_train:\" + str(x_train[0].shape))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print (\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
        "print (\"Number of labels in test data: \" + str(len(y_test)))\n",
        "print (\"Dimensions of single image in x_test:\" + str(x_test[0].shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples/observations in training data: 60000\n",
            "Number of labels in training data: 60000\n",
            "Dimensions of a single image in x_train:(28, 28)\n",
            "-------------------------------------------------------------\n",
            "Number of samples/observations in test data: 10000\n",
            "Number of labels in test data: 10000\n",
            "Dimensions of single image in x_test:(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "e7REostOiXdw",
        "outputId": "f8723c13-7cd3-4679-f35d-a2df93487774"
      },
      "source": [
        "# Visualization library to visualize images \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting 5 images, Subplot arugments represent nrows, ncols and index\n",
        "# Color map is set to grey since our image dataset is grayscale\n",
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(233)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(234)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(235)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSZqtmjjiay-",
        "outputId": "de8cc09f-d76d-41aa-a6e6-8f397d3201e2"
      },
      "source": [
        "#Import necessary keras specific libraries\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "# Setting Training Parameters like batch_size, epochs\n",
        "batch_size = 128\n",
        "epochs = 200\n",
        "\n",
        "# Storing the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "''' Getting the data in the right 'shape' as required by Keras i.e. adding a 4th \n",
        "dimension to our data thereby changing the original image shape of (60000,28,28) \n",
        "to (60000,28,28,1)'''\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Storing the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Changing image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing the data by changing the image pixel range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Performing one hot encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Calculate the number of classes and number of pixels \n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB3tcZPAilEX",
        "outputId": "af83d2ba-63d1-4493-bb69-5b73cf1073c7"
      },
      "source": [
        "model_fitting = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 11s 19ms/step - loss: 0.6010 - accuracy: 0.7989 - val_loss: 0.8466 - val_accuracy: 0.6903\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2894 - accuracy: 0.8977 - val_loss: 0.2527 - val_accuracy: 0.9061\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.2371 - accuracy: 0.9155 - val_loss: 0.2409 - val_accuracy: 0.9089\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2057 - accuracy: 0.9250 - val_loss: 0.2327 - val_accuracy: 0.9165\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1847 - accuracy: 0.9331 - val_loss: 0.2215 - val_accuracy: 0.9168\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1682 - accuracy: 0.9389 - val_loss: 0.2165 - val_accuracy: 0.9264\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.1529 - accuracy: 0.9444 - val_loss: 0.2184 - val_accuracy: 0.9239\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1357 - accuracy: 0.9504 - val_loss: 0.2248 - val_accuracy: 0.9220\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1257 - accuracy: 0.9545 - val_loss: 0.2542 - val_accuracy: 0.9159\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1148 - accuracy: 0.9575 - val_loss: 0.2309 - val_accuracy: 0.9283\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1086 - accuracy: 0.9610 - val_loss: 0.2183 - val_accuracy: 0.9302\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1005 - accuracy: 0.9639 - val_loss: 0.2352 - val_accuracy: 0.9235\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0891 - accuracy: 0.9684 - val_loss: 0.2243 - val_accuracy: 0.9270\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0847 - accuracy: 0.9687 - val_loss: 0.2517 - val_accuracy: 0.9271\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0784 - accuracy: 0.9717 - val_loss: 0.2343 - val_accuracy: 0.9240\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0767 - accuracy: 0.9720 - val_loss: 0.2370 - val_accuracy: 0.9297\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0715 - accuracy: 0.9729 - val_loss: 0.2518 - val_accuracy: 0.9306\n",
            "Epoch 18/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0718 - accuracy: 0.9737 - val_loss: 0.2659 - val_accuracy: 0.9262\n",
            "Epoch 19/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 0.2409 - val_accuracy: 0.9284\n",
            "Epoch 20/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.2453 - val_accuracy: 0.9306\n",
            "Epoch 21/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0569 - accuracy: 0.9795 - val_loss: 0.2821 - val_accuracy: 0.9267\n",
            "Epoch 22/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0625 - accuracy: 0.9768 - val_loss: 0.2710 - val_accuracy: 0.9276\n",
            "Epoch 23/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0564 - accuracy: 0.9786 - val_loss: 0.2771 - val_accuracy: 0.9311\n",
            "Epoch 24/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.3141 - val_accuracy: 0.9287\n",
            "Epoch 25/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.2858 - val_accuracy: 0.9311\n",
            "Epoch 26/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.2973 - val_accuracy: 0.9332\n",
            "Epoch 27/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0541 - accuracy: 0.9808 - val_loss: 0.2630 - val_accuracy: 0.9304\n",
            "Epoch 28/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0459 - accuracy: 0.9833 - val_loss: 0.2921 - val_accuracy: 0.9320\n",
            "Epoch 29/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 0.2759 - val_accuracy: 0.9328\n",
            "Epoch 30/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.3014 - val_accuracy: 0.9324\n",
            "Epoch 31/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0465 - accuracy: 0.9833 - val_loss: 0.3148 - val_accuracy: 0.9306\n",
            "Epoch 32/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0407 - accuracy: 0.9849 - val_loss: 0.3027 - val_accuracy: 0.9317\n",
            "Epoch 33/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.3042 - val_accuracy: 0.9267\n",
            "Epoch 34/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0390 - accuracy: 0.9859 - val_loss: 0.2959 - val_accuracy: 0.9324\n",
            "Epoch 35/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0361 - accuracy: 0.9867 - val_loss: 0.3015 - val_accuracy: 0.9339\n",
            "Epoch 36/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0364 - accuracy: 0.9864 - val_loss: 0.3236 - val_accuracy: 0.9304\n",
            "Epoch 37/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0342 - accuracy: 0.9873 - val_loss: 0.2828 - val_accuracy: 0.9308\n",
            "Epoch 38/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.3729 - val_accuracy: 0.9271\n",
            "Epoch 39/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0391 - accuracy: 0.9861 - val_loss: 0.3224 - val_accuracy: 0.9333\n",
            "Epoch 40/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0336 - accuracy: 0.9879 - val_loss: 0.3286 - val_accuracy: 0.9304\n",
            "Epoch 41/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 0.3347 - val_accuracy: 0.9318\n",
            "Epoch 42/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0346 - accuracy: 0.9873 - val_loss: 0.3077 - val_accuracy: 0.9309\n",
            "Epoch 43/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.3744 - val_accuracy: 0.9293\n",
            "Epoch 44/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.2996 - val_accuracy: 0.9286\n",
            "Epoch 45/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.3265 - val_accuracy: 0.9353\n",
            "Epoch 46/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 0.3013 - val_accuracy: 0.9320\n",
            "Epoch 47/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.2970 - val_accuracy: 0.9309\n",
            "Epoch 48/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.3455 - val_accuracy: 0.9318\n",
            "Epoch 49/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.3437 - val_accuracy: 0.9321\n",
            "Epoch 50/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 0.3361 - val_accuracy: 0.9312\n",
            "Epoch 51/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0301 - accuracy: 0.9891 - val_loss: 0.3688 - val_accuracy: 0.9337\n",
            "Epoch 52/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0286 - accuracy: 0.9893 - val_loss: 0.3267 - val_accuracy: 0.9334\n",
            "Epoch 53/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.3279 - val_accuracy: 0.9234\n",
            "Epoch 54/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.3569 - val_accuracy: 0.9313\n",
            "Epoch 55/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0277 - accuracy: 0.9897 - val_loss: 0.3438 - val_accuracy: 0.9319\n",
            "Epoch 56/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0280 - accuracy: 0.9899 - val_loss: 0.3280 - val_accuracy: 0.9337\n",
            "Epoch 57/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.3329 - val_accuracy: 0.9317\n",
            "Epoch 58/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.3514 - val_accuracy: 0.9314\n",
            "Epoch 59/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.3121 - val_accuracy: 0.9313\n",
            "Epoch 60/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.3755 - val_accuracy: 0.9307\n",
            "Epoch 61/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.3264 - val_accuracy: 0.9335\n",
            "Epoch 62/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.3451 - val_accuracy: 0.9331\n",
            "Epoch 63/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.3261 - val_accuracy: 0.9309\n",
            "Epoch 64/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0256 - accuracy: 0.9902 - val_loss: 0.3433 - val_accuracy: 0.9332\n",
            "Epoch 65/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0220 - accuracy: 0.9919 - val_loss: 0.3472 - val_accuracy: 0.9320\n",
            "Epoch 66/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.3434 - val_accuracy: 0.9315\n",
            "Epoch 67/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0231 - accuracy: 0.9914 - val_loss: 0.3202 - val_accuracy: 0.9306\n",
            "Epoch 68/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.3660 - val_accuracy: 0.9348\n",
            "Epoch 69/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.3168 - val_accuracy: 0.9319\n",
            "Epoch 70/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.3330 - val_accuracy: 0.9315\n",
            "Epoch 71/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.3671 - val_accuracy: 0.9307\n",
            "Epoch 72/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.3791 - val_accuracy: 0.9316\n",
            "Epoch 73/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.4338 - val_accuracy: 0.9319\n",
            "Epoch 74/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.3380 - val_accuracy: 0.9373\n",
            "Epoch 75/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.4190 - val_accuracy: 0.9328\n",
            "Epoch 76/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 0.3476 - val_accuracy: 0.9301\n",
            "Epoch 77/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0224 - accuracy: 0.9913 - val_loss: 0.3443 - val_accuracy: 0.9300\n",
            "Epoch 78/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0208 - accuracy: 0.9923 - val_loss: 0.3991 - val_accuracy: 0.9365\n",
            "Epoch 79/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.3496 - val_accuracy: 0.9333\n",
            "Epoch 80/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.3471 - val_accuracy: 0.9319\n",
            "Epoch 81/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.3856 - val_accuracy: 0.9334\n",
            "Epoch 82/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.3698 - val_accuracy: 0.9319\n",
            "Epoch 83/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.3808 - val_accuracy: 0.9347\n",
            "Epoch 84/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.3947 - val_accuracy: 0.9348\n",
            "Epoch 85/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.3618 - val_accuracy: 0.9333\n",
            "Epoch 86/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.3559 - val_accuracy: 0.9347\n",
            "Epoch 87/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.3891 - val_accuracy: 0.9340\n",
            "Epoch 88/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 0.3699 - val_accuracy: 0.9349\n",
            "Epoch 89/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.3367 - val_accuracy: 0.9330\n",
            "Epoch 90/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.3596 - val_accuracy: 0.9343\n",
            "Epoch 91/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.3696 - val_accuracy: 0.9353\n",
            "Epoch 92/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.3793 - val_accuracy: 0.9309\n",
            "Epoch 93/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.3855 - val_accuracy: 0.9328\n",
            "Epoch 94/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.3620 - val_accuracy: 0.9315\n",
            "Epoch 95/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.3543 - val_accuracy: 0.9314\n",
            "Epoch 96/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.3382 - val_accuracy: 0.9325\n",
            "Epoch 97/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.3961 - val_accuracy: 0.9326\n",
            "Epoch 98/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.3639 - val_accuracy: 0.9327\n",
            "Epoch 99/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.4663 - val_accuracy: 0.9300\n",
            "Epoch 100/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.3736 - val_accuracy: 0.9323\n",
            "Epoch 101/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.4169 - val_accuracy: 0.9331\n",
            "Epoch 102/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.5153 - val_accuracy: 0.9313\n",
            "Epoch 103/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.4242 - val_accuracy: 0.9343\n",
            "Epoch 104/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.3969 - val_accuracy: 0.9338\n",
            "Epoch 105/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.3934 - val_accuracy: 0.9320\n",
            "Epoch 106/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0187 - accuracy: 0.9929 - val_loss: 0.3571 - val_accuracy: 0.9367\n",
            "Epoch 107/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.3489 - val_accuracy: 0.9320\n",
            "Epoch 108/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.3910 - val_accuracy: 0.9320\n",
            "Epoch 109/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.4492 - val_accuracy: 0.9337\n",
            "Epoch 110/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.4163 - val_accuracy: 0.9343\n",
            "Epoch 111/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0181 - accuracy: 0.9935 - val_loss: 0.4457 - val_accuracy: 0.9332\n",
            "Epoch 112/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.4607 - val_accuracy: 0.9323\n",
            "Epoch 113/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.3886 - val_accuracy: 0.9352\n",
            "Epoch 114/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.4442 - val_accuracy: 0.9358\n",
            "Epoch 115/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.4137 - val_accuracy: 0.9323\n",
            "Epoch 116/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.4069 - val_accuracy: 0.9353\n",
            "Epoch 117/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.3594 - val_accuracy: 0.9360\n",
            "Epoch 118/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.3730 - val_accuracy: 0.9341\n",
            "Epoch 119/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.3611 - val_accuracy: 0.9337\n",
            "Epoch 120/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.3947 - val_accuracy: 0.9352\n",
            "Epoch 121/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.4931 - val_accuracy: 0.9341\n",
            "Epoch 122/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.4370 - val_accuracy: 0.9361\n",
            "Epoch 123/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0168 - accuracy: 0.9934 - val_loss: 0.4178 - val_accuracy: 0.9329\n",
            "Epoch 124/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.3571 - val_accuracy: 0.9304\n",
            "Epoch 125/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.4034 - val_accuracy: 0.9355\n",
            "Epoch 126/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.3901 - val_accuracy: 0.9365\n",
            "Epoch 127/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.4101 - val_accuracy: 0.9366\n",
            "Epoch 128/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.3868 - val_accuracy: 0.9344\n",
            "Epoch 129/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0164 - accuracy: 0.9938 - val_loss: 0.3925 - val_accuracy: 0.9357\n",
            "Epoch 130/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.4145 - val_accuracy: 0.9361\n",
            "Epoch 131/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.4293 - val_accuracy: 0.9321\n",
            "Epoch 132/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.3655 - val_accuracy: 0.9357\n",
            "Epoch 133/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.3822 - val_accuracy: 0.9356\n",
            "Epoch 134/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.4526 - val_accuracy: 0.9344\n",
            "Epoch 135/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.4141 - val_accuracy: 0.9351\n",
            "Epoch 136/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.4504 - val_accuracy: 0.9351\n",
            "Epoch 137/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.4903 - val_accuracy: 0.9339\n",
            "Epoch 138/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.4018 - val_accuracy: 0.9345\n",
            "Epoch 139/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.4264 - val_accuracy: 0.9348\n",
            "Epoch 140/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.4068 - val_accuracy: 0.9355\n",
            "Epoch 141/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.4324 - val_accuracy: 0.9331\n",
            "Epoch 142/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.3408 - val_accuracy: 0.9299\n",
            "Epoch 143/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.4514 - val_accuracy: 0.9375\n",
            "Epoch 144/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.4043 - val_accuracy: 0.9356\n",
            "Epoch 145/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.3781 - val_accuracy: 0.9338\n",
            "Epoch 146/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.3847 - val_accuracy: 0.9335\n",
            "Epoch 147/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.3582 - val_accuracy: 0.9329\n",
            "Epoch 148/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.5075 - val_accuracy: 0.9356\n",
            "Epoch 149/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.4156 - val_accuracy: 0.9370\n",
            "Epoch 150/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.4260 - val_accuracy: 0.9332\n",
            "Epoch 151/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.3933 - val_accuracy: 0.9350\n",
            "Epoch 152/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.4274 - val_accuracy: 0.9304\n",
            "Epoch 153/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.3917 - val_accuracy: 0.9370\n",
            "Epoch 154/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.4004 - val_accuracy: 0.9371\n",
            "Epoch 155/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.4558 - val_accuracy: 0.9341\n",
            "Epoch 156/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.4856 - val_accuracy: 0.9328\n",
            "Epoch 157/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.4708 - val_accuracy: 0.9360\n",
            "Epoch 158/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.3971 - val_accuracy: 0.9346\n",
            "Epoch 159/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.4467 - val_accuracy: 0.9346\n",
            "Epoch 160/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.4310 - val_accuracy: 0.9344\n",
            "Epoch 161/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.4174 - val_accuracy: 0.9338\n",
            "Epoch 162/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.3722 - val_accuracy: 0.9340\n",
            "Epoch 163/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.4328 - val_accuracy: 0.9333\n",
            "Epoch 164/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.4626 - val_accuracy: 0.9350\n",
            "Epoch 165/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.4183 - val_accuracy: 0.9359\n",
            "Epoch 166/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.4389 - val_accuracy: 0.9351\n",
            "Epoch 167/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.4367 - val_accuracy: 0.9341\n",
            "Epoch 168/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.3505 - val_accuracy: 0.9316\n",
            "Epoch 169/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4505 - val_accuracy: 0.9337\n",
            "Epoch 170/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.4520 - val_accuracy: 0.9360\n",
            "Epoch 171/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.4138 - val_accuracy: 0.9354\n",
            "Epoch 172/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.4720 - val_accuracy: 0.9348\n",
            "Epoch 173/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.4529 - val_accuracy: 0.9352\n",
            "Epoch 174/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.3611 - val_accuracy: 0.9350\n",
            "Epoch 175/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.4313 - val_accuracy: 0.9378\n",
            "Epoch 176/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.4560 - val_accuracy: 0.9335\n",
            "Epoch 177/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.4503 - val_accuracy: 0.9359\n",
            "Epoch 178/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.4143 - val_accuracy: 0.9347\n",
            "Epoch 179/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.4316 - val_accuracy: 0.9347\n",
            "Epoch 180/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.4018 - val_accuracy: 0.9354\n",
            "Epoch 181/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5089 - val_accuracy: 0.9365\n",
            "Epoch 182/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.4029 - val_accuracy: 0.9350\n",
            "Epoch 183/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.4296 - val_accuracy: 0.9355\n",
            "Epoch 184/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.4122 - val_accuracy: 0.9357\n",
            "Epoch 185/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.4169 - val_accuracy: 0.9354\n",
            "Epoch 186/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.3991 - val_accuracy: 0.9373\n",
            "Epoch 187/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.4191 - val_accuracy: 0.9348\n",
            "Epoch 188/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.3719 - val_accuracy: 0.9366\n",
            "Epoch 189/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4143 - val_accuracy: 0.9362\n",
            "Epoch 190/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.3864 - val_accuracy: 0.9361\n",
            "Epoch 191/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.4524 - val_accuracy: 0.9367\n",
            "Epoch 192/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.5168 - val_accuracy: 0.9362\n",
            "Epoch 193/200\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.4406 - val_accuracy: 0.9359\n",
            "Epoch 194/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.4246 - val_accuracy: 0.9335\n",
            "Epoch 195/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.4134 - val_accuracy: 0.9357\n",
            "Epoch 196/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.4714 - val_accuracy: 0.9356\n",
            "Epoch 197/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.4411 - val_accuracy: 0.9368\n",
            "Epoch 198/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.4184 - val_accuracy: 0.9294\n",
            "Epoch 199/200\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.3656 - val_accuracy: 0.9345\n",
            "Epoch 200/200\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.3725 - val_accuracy: 0.9350\n",
            "Test loss: 0.37254273891448975\n",
            "Test accuracy: 0.9350000023841858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYXDnuSMi6ZB",
        "outputId": "2de490c8-44f2-4e19-e44b-d09cab27e0eb"
      },
      "source": [
        "# Configuration related preprocessing step before mounting the drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST3MPQ27WTmH",
        "outputId": "5224f89a-a37c-40c6-aebd-a5fcc63f16dc"
      },
      "source": [
        "#Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTIC0TLIWUaI"
      },
      "source": [
        "\n",
        "# Change the directory to current working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn7BTigBWnEo"
      },
      "source": [
        "\n",
        "# Save the model with the name clothing_classification_model\n",
        "model.save('clothing_classification_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD1XTi_wWuzw",
        "outputId": "f21e4617-6366-4752-fbf1-3cd17c9f832e"
      },
      "source": [
        "# Import few more necessary libraries.\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Function to load and prepare the image in right shape\n",
        "def load_image(filename):\n",
        "\t# Load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# Convert the image to array\n",
        "\timg = img_to_array(img)\n",
        "\t# Reshape the image into a sample of 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# Prepare it as pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# Load an image and predict the apparel class\n",
        "img = load_image('trouser.jpg')\n",
        "# Load the saved model\n",
        "model = load_model('clothing_classification_model.h5')\n",
        "# Predict the apparel class\n",
        "class_prediction = model.predict_classes(img)\n",
        "print(class_prediction[0])\n",
        "\n",
        "#Map apparel category with the numerical class\n",
        "if class_prediction[0] == 0:\n",
        "  product = \"T-shirt/top\"\n",
        "elif class_prediction[0] == 1:\n",
        "  product = \"Trouser\"\n",
        "elif class_prediction[0] == 2:\n",
        "  product = \"Pullover\"\n",
        "elif class_prediction[0] == 3:\n",
        "  product = \"Dress\"\n",
        "elif class_prediction[0] == 4:\n",
        "  product = \"Coat\"\n",
        "elif class_prediction[0] == 5:\n",
        "  product = \"Sandal\"\n",
        "elif class_prediction[0] == 6:\n",
        "  product = \"Shirt\"\n",
        "elif class_prediction[0] == 7:\n",
        "  product = \"Sneaker\"\n",
        "elif class_prediction[0] == 8:\n",
        "  product = \"Bag\"\n",
        "else:\n",
        "  product = \"Ankle boot\"\n",
        "\n",
        "print(product)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Trouser\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY8TTZDnW1Ff"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
